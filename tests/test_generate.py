#!/usr/bin/env python3
"""
Phase 2 í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - ì›¹ ì¸í„°í˜ì´ìŠ¤ ì—†ì´ ë¸”ë¡œê·¸ ê¸€ ìƒì„± íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

ì‚¬ìš©ë²•:
    python3 scripts/test_generate.py [project_id]

ì˜ˆì‹œ:
    python3 scripts/test_generate.py 20260207_001
    python3 scripts/test_generate.py  # ê¸°ë³¸ê°’: 20260207_001 ì‚¬ìš©
"""

import sys
import json
import os
import stat
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€ (scripts/ ì•„ë˜ë¡œ ì´ë™í–ˆê¸° ë•Œë¬¸)
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))
os.chdir(PROJECT_ROOT)

try:
    from src.content.models import (
        MetaJsonData, AnalysisJsonData, GenerationReadyData,
        UserDirectInput, PipelineLogEntry
    )
    from src.content.experience_processor import ExperienceProcessor
    from src.content.blog_generator import HashtagGenerator, ContentStructureBuilder
    from src.utils.exceptions import FileProcessingError
    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Some modules not available: {e}")
    print("Running in basic mode without full functionality")
    MODULES_AVAILABLE = False

class PipelineRunner:
    """í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í´ë˜ìŠ¤"""

    def __init__(self, project_id: str):
        self.project_id = project_id
        self.project_dir = Path(f"data/{project_id}")
        self.meta_path = self.project_dir / "meta.json"
        self.analysis_path = self.project_dir / "analysis.json"
        self.generation_ready_path = self.project_dir / "generation_ready.json"
        self.logs_dir = self.project_dir / "logs"

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.logs_dir.mkdir(parents=True, exist_ok=True)

    def log_event(self, stage: str, status: str, message: str, confidence: Optional[float] = None):
        """êµ¬ì¡°í™”ëœ ë¡œê·¸ ê¸°ë¡"""
        log_entry = PipelineLogEntry(
            stage=stage,
            status=status,
            message=message,
            confidence=confidence
        )

        # ì½˜ì†” ì¶œë ¥
        print(f"[{log_entry.timestamp}] {stage.upper()} - {status}: {message}")
        if confidence is not None:
            print(f"  â””â”€ Confidence: {confidence:.2f}")

        # JSON ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
        log_file = self.logs_dir / "pipeline_log.json"

        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
        else:
            logs = []

        logs.append(log_entry.model_dump(mode='json'))

        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, ensure_ascii=False, indent=2, default=str)

    def load_and_validate_meta(self) -> MetaJsonData:
        """meta.json ë¡œë“œ ë° ê²€ì¦"""
        self.log_event("meta_loading", "info", f"Loading meta.json from {self.meta_path}")

        if not self.meta_path.exists():
            raise FileProcessingError(
                f"meta.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.meta_path}",
                file_path=str(self.meta_path)
            )

        try:
            with open(self.meta_path, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)

            # Pydantic ëª¨ë¸ë¡œ ê²€ì¦
            validated_meta = MetaJsonData(**meta_data)

            self.log_event("meta_loading", "completed", "meta.json ë¡œë“œ ë° ê²€ì¦ ì™„ë£Œ")
            return validated_meta

        except Exception as e:
            self.log_event("meta_loading", "failed", f"meta.json ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise FileProcessingError(f"meta.json ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", str(self.meta_path))

    def check_images_exist(self, meta_data: MetaJsonData) -> Dict[str, bool]:
        """ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸"""
        self.log_event("image_check", "info", "ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸ ì¤‘")

        images_status = {}
        images_dir = self.project_dir / "images"

        for filename in meta_data.images:
            image_path = images_dir / filename
            exists = image_path.exists()
            images_status[filename] = exists

            if exists:
                file_size = image_path.stat().st_size
                self.log_event("image_check", "info", f"ì´ë¯¸ì§€ ë°œê²¬: {filename} ({file_size} bytes)")
            else:
                self.log_event("image_check", "warning", f"ì´ë¯¸ì§€ ëˆ„ë½: {filename}")

        found_count = sum(images_status.values())
        total_count = len(images_status)

        self.log_event("image_check", "completed", f"ì´ë¯¸ì§€ í™•ì¸ ì™„ë£Œ: {found_count}/{total_count} ë°œê²¬")

        return images_status

    def run_exif_analysis(self, meta_data: MetaJsonData) -> Dict[str, Any]:
        """EXIF ë¶„ì„ ì‹¤í–‰"""
        self.log_event("exif_analysis", "info", "EXIF ë°ì´í„° ì¶”ì¶œ ì‹œì‘")

        if not MODULES_AVAILABLE:
            # Fallback to mock data
            exif_result = {
                "gps_found": False,
                "coordinates": None,
                "exif_confidence": 0.0,
                "extraction_method": "mock_fallback",
                "raw_exif_data": {}
            }
            self.log_event("exif_analysis", "completed", "EXIF ë¶„ì„ ì™„ë£Œ (Fallback)", confidence=0.0)
            return exif_result

        # ì‹¤ì œ EXIF ì²˜ë¦¬ê¸° ì‚¬ìš©
        processor = ExperienceProcessor(self.project_dir)
        result = processor.process_user_experience(meta_data.user_input, meta_data.images)

        exif_result = result["location_analysis"]["exif_results"]
        confidence = exif_result.get("exif_confidence", 0.0)

        self.log_event("exif_analysis", "completed", "EXIF ë¶„ì„ ì™„ë£Œ", confidence=confidence)
        return exif_result

    def run_location_inference(self, meta_data: MetaJsonData, exif_result: Dict[str, Any]) -> Dict[str, Any]:
        """ìœ„ì¹˜ ì¶”ë¡  ì‹¤í–‰"""
        self.log_event("location_inference", "info", "í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ„ì¹˜ ì¶”ë¡  ì‹œì‘")

        if not MODULES_AVAILABLE:
            # Fallback to simple pattern matching
            personal_review = meta_data.user_input.personal_review
            location = None
            confidence = 0.0
            matched_patterns = []

            if "ê°•ë‚¨ì—­" in personal_review:
                location = "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ê°•ë‚¨ì—­ ê·¼ì²˜"
                confidence = 0.85
                matched_patterns = ["ê°•ë‚¨ì—­"]
            elif "í™ëŒ€" in personal_review:
                location = "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ í™ëŒ€ ê·¼ì²˜"
                confidence = 0.80
                matched_patterns = ["í™ëŒ€"]

            text_analysis = {
                "detected_location": location,
                "extraction_method": "fallback_pattern_matching",
                "matched_patterns": matched_patterns,
                "text_confidence": confidence,
                "candidate_locations": matched_patterns
            }

            final_location = {
                "location": location,
                "coordinates": None,
                "source": "text" if location else "none",
                "confidence": confidence
            }
        else:
            # ì‹¤ì œ ìœ„ì¹˜ ì¶”ë¡  ì—”ì§„ ì‚¬ìš©
            processor = ExperienceProcessor(self.project_dir)
            result = processor.process_user_experience(meta_data.user_input, meta_data.images)
            location_analysis = result["location_analysis"]

            text_analysis = location_analysis["text_analysis"]
            final_location = location_analysis["final_location"]

        status = "completed"
        message = f"ìœ„ì¹˜ ì¶”ë¡  ì™„ë£Œ: {final_location.get('detected_location') or final_location.get('location') or 'ì¶”ë¡  ì‹¤íŒ¨'}"
        self.log_event("location_inference", status, message, confidence=final_location['confidence'])

        return {
            "exif_results": exif_result,
            "text_analysis": text_analysis,
            "final_location": final_location
        }

    def run_hashtag_generation(self, meta_data: MetaJsonData, location_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """í•´ì‹œíƒœê·¸ ìƒì„± ì‹¤í–‰"""
        self.log_event("hashtag_generation", "info", "í•´ì‹œíƒœê·¸ ìë™ ìƒì„± ì‹œì‘")

        user_input = meta_data.user_input
        final_location_data = location_analysis["final_location"]

        if not MODULES_AVAILABLE:
            # Fallback to simple rule-based generation
            candidates = self._generate_simple_hashtags(user_input, final_location_data.get("detected_location") or final_location_data.get("location"))
            refined_tags = {
                "deduplicated": list(dict.fromkeys([tag for tags in candidates.values() for tag in tags])),
                "semantic_filtered": list(dict.fromkeys([tag for tags in candidates.values() for tag in tags])),
                "final_tags": list(dict.fromkeys([tag for tags in candidates.values() for tag in tags]))[:6]
            }
            confidence = 0.8 if refined_tags["final_tags"] else 0.0
        else:
            # ì‹¤ì œ í•´ì‹œíƒœê·¸ ìƒì„±ê¸° ì‚¬ìš©
            from src.content.models import LocationInfo

            # LocationInfo ê°ì²´ ìƒì„±
            location_info = LocationInfo(
                detected_location=final_location_data.get("detected_location") or final_location_data.get("location"),
                coordinates=final_location_data.get("coordinates"),
                source=final_location_data["source"],
                confidence=final_location_data["confidence"]
            )

            # í‚¤ì›Œë“œ ì¶”ì¶œ
            processor = ExperienceProcessor(self.project_dir)
            result = processor.process_user_experience(user_input, meta_data.images)
            extracted_keywords = result.get("extracted_keywords", [])

            # í•´ì‹œíƒœê·¸ í›„ë³´ ìƒì„±
            candidates_obj = HashtagGenerator.generate_candidate_hashtags(user_input, location_info, extracted_keywords)
            candidates = candidates_obj.model_dump()

            # í•´ì‹œíƒœê·¸ ì •ì œ
            refined_result = HashtagGenerator.refine_hashtags(candidates_obj)
            refined_tags = refined_result.model_dump()

            confidence = 0.92 if refined_tags["final_tags"] else 0.0

        self.log_event("hashtag_generation", "completed", f"í•´ì‹œíƒœê·¸ ìƒì„± ì™„ë£Œ: {len(refined_tags['final_tags'])}ê°œ", confidence=confidence)

        return {
            "candidate_tags": candidates,
            "refined_tags": refined_tags,
            "tag_confidence": confidence
        }

    def _generate_simple_hashtags(self, user_input: UserDirectInput, location: Optional[str]) -> Dict[str, List[str]]:
        """ê°„ë‹¨í•œ í•´ì‹œíƒœê·¸ ìƒì„± (Fallback)"""
        candidates = {
            "category_based": [],
            "rating_based": [],
            "companion_based": [],
            "keyword_based": [],
            "location_based": []
        }

        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜
        if user_input.category == "ë§›ì§‘":
            candidates["category_based"] = ["#ë§›ì§‘", "#ìŒì‹"]

        # ë³„ì  ê¸°ë°˜
        if user_input.rating == 5:
            candidates["rating_based"] = ["#ê°•ì¶”", "#ìµœê³ "]
        elif user_input.rating == 4:
            candidates["rating_based"] = ["#ì¶”ì²œ", "#ì¢‹ì•„ìš”"]

        # ë™í–‰ì ê¸°ë°˜
        if user_input.companion == "ê°€ì¡±":
            candidates["companion_based"] = ["#ê°€ì¡±ì‹ì‚¬"]

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        review = user_input.personal_review
        if "ì´íƒˆë¦¬ì•ˆ" in review:
            candidates["keyword_based"].append("#ì´íƒˆë¦¬ì•ˆ")
        if "íŒŒìŠ¤íƒ€" in review:
            candidates["keyword_based"].append("#íŒŒìŠ¤íƒ€")
        if "ì•Œë¦¬ì˜¤ì˜¬ë¦¬ì˜¤" in review:
            candidates["keyword_based"].append("#ì•Œë¦¬ì˜¤ì˜¬ë¦¬ì˜¤")

        # ìœ„ì¹˜ ê¸°ë°˜ (locationì´ Noneì´ ì•„ë‹ ë•Œë§Œ)
        if location:
            if "ê°•ë‚¨" in location:
                candidates["location_based"] = ["#ê°•ë‚¨ë§›ì§‘"]

        return candidates

    def save_analysis_results(self, meta_data: MetaJsonData, location_analysis: Dict[str, Any], hashtag_analysis: Dict[str, Any]):
        """analysis.json ì €ì¥"""
        self.log_event("save_analysis", "info", f"analysis.json ì €ì¥ ì¤‘: {self.analysis_path}")

        analysis_data = AnalysisJsonData(
            project_id=meta_data.project_id,
            location_analysis=location_analysis,
            hashtag_analysis=hashtag_analysis,
            confidence_scores={
                "location_detection": location_analysis["final_location"]["confidence"],
                "hashtag_generation": hashtag_analysis["tag_confidence"],
                "overall_analysis": (location_analysis["final_location"]["confidence"] + hashtag_analysis["tag_confidence"]) / 2
            },
            processing_metadata={
                "exif_parsing_status": "completed",
                "location_inference_status": "completed",
                "hashtag_generation_status": "completed"
            }
        )

        with open(self.analysis_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_data.model_dump(mode='json'), f, ensure_ascii=False, indent=2, default=str)

        self.log_event("save_analysis", "completed", "analysis.json ì €ì¥ ì™„ë£Œ")

    def save_generation_ready_data(self, meta_data: MetaJsonData, analysis_data: Dict[str, Any]):
        """generation_ready.json ì €ì¥ (confidence ì œì™¸)"""
        self.log_event("save_generation_ready", "info", f"generation_ready.json ì €ì¥ ì¤‘: {self.generation_ready_path}")

        # analysis.jsonì—ì„œ ìµœì¢… ë°ì´í„° ì¶”ì¶œ
        final_location = analysis_data["location_analysis"]["final_location"]
        location = final_location.get("detected_location") or final_location.get("location")
        hashtags = analysis_data["hashtag_analysis"]["refined_tags"]["final_tags"]

        merged_data = {
            "category": meta_data.user_input.category,
            "rating": meta_data.user_input.rating,
            "visit_date": meta_data.user_input.visit_date,
            "companion": meta_data.user_input.companion,
            "personal_review": meta_data.user_input.personal_review,
            "ai_additional_script": meta_data.user_input.ai_additional_script,
            "location": location,  # None ê°€ëŠ¥
            "hashtags": hashtags,
            "images": meta_data.images
        }

        generation_ready = GenerationReadyData(
            project_id=meta_data.project_id,
            merged_data=merged_data,
            generation_settings=meta_data.settings
        )

        with open(self.generation_ready_path, 'w', encoding='utf-8') as f:
            json.dump(generation_ready.model_dump(mode='json'), f, ensure_ascii=False, indent=2, default=str)

        self.log_event("save_generation_ready", "completed", "generation_ready.json ì €ì¥ ì™„ë£Œ")

    def make_meta_readonly(self):
        """meta.jsonì„ ì½ê¸° ì „ìš©ìœ¼ë¡œ ì„¤ì •"""
        if self.meta_path.exists():
            os.chmod(self.meta_path, stat.S_IREAD)
            self.log_event("meta_protection", "completed", "meta.json ì½ê¸° ì „ìš©ìœ¼ë¡œ ì„¤ì •")

    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            print(f"\nğŸš€ Phase 2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            print(f"   í”„ë¡œì íŠ¸ ID: {self.project_id}")
            print(f"   í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.project_dir}")
            print("=" * 60)

            # 1. meta.json ë¡œë“œ ë° ê²€ì¦
            meta_data = self.load_and_validate_meta()

            # 2. ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
            images_status = self.check_images_exist(meta_data)

            # 3. meta.json ì½ê¸° ì „ìš© ì„¤ì •
            self.make_meta_readonly()

            # 4. EXIF ë¶„ì„
            exif_result = self.run_exif_analysis(meta_data)

            # 5. ìœ„ì¹˜ ì¶”ë¡ 
            location_analysis = self.run_location_inference(meta_data, exif_result)

            # 6. í•´ì‹œíƒœê·¸ ìƒì„±
            hashtag_analysis = self.run_hashtag_generation(meta_data, location_analysis)

            # 7. analysis.json ì €ì¥
            analysis_full = {
                "location_analysis": location_analysis,
                "hashtag_analysis": hashtag_analysis
            }
            self.save_analysis_results(meta_data, location_analysis, hashtag_analysis)

            # 8. generation_ready.json ì €ì¥
            self.save_generation_ready_data(meta_data, analysis_full)

            print("\nâœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            print("=" * 60)

            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            final_location_data = location_analysis["final_location"]
            final_location = final_location_data.get("detected_location") or final_location_data.get("location")
            final_hashtags = hashtag_analysis["refined_tags"]["final_tags"]

            print(f"ğŸ“ ì¶”ë¡ ëœ ìœ„ì¹˜: {final_location or 'ì¶”ë¡  ì‹¤íŒ¨'}")
            print(f"ğŸ·ï¸  ìƒì„±ëœ í•´ì‹œíƒœê·¸: {', '.join(final_hashtags) if final_hashtags else 'ì—†ìŒ'}")
            print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
            print(f"   - {self.analysis_path}")
            print(f"   - {self.generation_ready_path}")
            print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {self.logs_dir / 'pipeline_log.json'}")

            self.log_event("pipeline", "completed", "ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ")

        except Exception as e:
            self.log_event("pipeline", "failed", f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        project_id = sys.argv[1]
    else:
        project_id = "20260207_001"

    print(f"Phase 2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ - í”„ë¡œì íŠ¸ ID: {project_id}")

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    runner = PipelineRunner(project_id)
    runner.run_full_pipeline()


if __name__ == "__main__":
    main()
