"""
ì‹¤ì‹œê°„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° í”¼ë“œë°± ì‹œìŠ¤í…œ

ìƒì„±ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸ ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¢…í•©ì ì¸ í’ˆì§ˆ ì ìˆ˜ë¥¼ ì œê³µí•˜ê³ ,
ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì •ì±… ì¤€ìˆ˜ ë° í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import json

try:
    from .naver_validator import NaverQualityValidator
    from .keyword_analyzer import KeywordDensityAnalyzer
    from .content_checker import ContentQualityChecker
except ImportError:
    # ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì§ì ‘ ì‹¤í–‰í•  ë•Œ
    from naver_validator import NaverQualityValidator
    from keyword_analyzer import KeywordDensityAnalyzer
    from content_checker import ContentQualityChecker


class UnifiedQualityScorer:
    """í†µí•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°ê¸°"""

    # ê° ê²€ì¦ ì˜ì—­ì˜ ê°€ì¤‘ì¹˜ ì„¤ì •
    VALIDATION_WEIGHTS = {
        "naver_compliance": 0.35,      # ë„¤ì´ë²„ ì •ì±… ì¤€ìˆ˜ (35%)
        "keyword_quality": 0.25,       # í‚¤ì›Œë“œ í’ˆì§ˆ (25%)
        "personal_authenticity": 0.25, # ê°œì¸ ê²½í—˜ ì§„ì •ì„± (25%)
        "technical_quality": 0.15      # ê¸°ìˆ ì  í’ˆì§ˆ (15%)
    }

    # í’ˆì§ˆ ë“±ê¸‰ ê¸°ì¤€ì 
    QUALITY_THRESHOLDS = {
        "EXCELLENT": 0.9,
        "VERY_GOOD": 0.8,
        "GOOD": 0.7,
        "FAIR": 0.6,
        "POOR": 0.5,
        "VERY_POOR": 0.0
    }

    # ë„¤ì´ë²„ ì •ì±… í†µê³¼ ê¸°ì¤€
    NAVER_PASS_THRESHOLD = 0.75

    def __init__(self):
        """í†µí•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°ê¸° ì´ˆê¸°í™”"""
        self.naver_validator = NaverQualityValidator()
        self.keyword_analyzer = KeywordDensityAnalyzer()
        self.content_checker = ContentQualityChecker()

    def calculate_unified_score(self,
                              generated_content: str,
                              original_review: Optional[str] = None,
                              target_keywords: Optional[List[str]] = None,
                              category: Optional[str] = None) -> Dict[str, Any]:
        """
        í†µí•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

        Args:
            generated_content: ìƒì„±ëœ ë¸”ë¡œê·¸ ê¸€
            original_review: ì›ë³¸ ì‚¬ìš©ì ë¦¬ë·° (ê°œì¸ ê²½í—˜ ë¶„ì„ìš©)
            target_keywords: ëŒ€ìƒ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ë°€ë„ ë¶„ì„ìš©)
            category: ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ (ë§›ì§‘, ì œí’ˆ ë“±)

        Returns:
            í†µí•© í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        analysis_start_time = datetime.now()

        # 1. ë„¤ì´ë²„ ì •ì±… ì¤€ìˆ˜ ê²€ì¦
        naver_analysis = self._run_naver_validation(generated_content)

        # 2. í‚¤ì›Œë“œ í’ˆì§ˆ ë¶„ì„
        keyword_analysis = self._run_keyword_analysis(generated_content, target_keywords)

        # 3. ê°œì¸ ê²½í—˜ ì§„ì •ì„± ë¶„ì„ (ì›ë³¸ ë¦¬ë·°ê°€ ìˆì„ ë•Œë§Œ)
        personal_analysis = None
        if original_review:
            personal_analysis = self._run_personal_analysis(generated_content, original_review, category)

        # 4. ê¸°ìˆ ì  í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
        technical_analysis = self._calculate_technical_quality(generated_content, naver_analysis, keyword_analysis)

        # 5. í†µí•© ì ìˆ˜ ê³„ì‚°
        unified_score = self._calculate_unified_quality_score(
            naver_analysis, keyword_analysis, personal_analysis, technical_analysis
        )

        # 6. ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±
        real_time_feedback = self._generate_real_time_feedback(
            unified_score, naver_analysis, keyword_analysis, personal_analysis
        )

        analysis_duration = (datetime.now() - analysis_start_time).total_seconds()

        return {
            "timestamp": datetime.now().isoformat(),
            "analysis_duration_seconds": round(analysis_duration, 3),
            "content_length": len(generated_content),
            "content_word_count": len(generated_content.split()),

            # í†µí•© ê²°ê³¼
            "unified_score": unified_score,

            # ì„¸ë¶€ ë¶„ì„ ê²°ê³¼
            "naver_compliance_analysis": naver_analysis,
            "keyword_quality_analysis": keyword_analysis,
            "personal_authenticity_analysis": personal_analysis,
            "technical_quality_analysis": technical_analysis,

            # ì‹¤ì‹œê°„ í”¼ë“œë°±
            "real_time_feedback": real_time_feedback,

            # ë©”íƒ€ë°ì´í„°
            "analysis_metadata": {
                "has_original_review": original_review is not None,
                "has_target_keywords": target_keywords is not None,
                "category": category,
                "validation_components_used": [
                    "naver_validator",
                    "keyword_analyzer",
                    "content_checker" if original_review else None,
                    "technical_analyzer"
                ]
            }
        }

    def _run_naver_validation(self, content: str) -> Dict[str, Any]:
        """ë„¤ì´ë²„ ì •ì±… ì¤€ìˆ˜ ê²€ì¦ ì‹¤í–‰"""
        try:
            validation_result = self.naver_validator.validate_content(content)
            risk_assessment = validation_result.get("risk_assessment", {})

            return {
                "success": True,
                "quality_score": risk_assessment.get("quality_score", 0) / 100.0,  # 0-1 ë²”ìœ„ë¡œ ë³€í™˜
                "risk_level": risk_assessment.get("risk_level", "UNKNOWN"),
                "risk_score": risk_assessment.get("overall_risk_score", 1.0),
                "passed": risk_assessment.get("passed", False),
                "validation_details": validation_result.get("validations", {}),
                "recommendations": risk_assessment.get("recommendations", [])
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "quality_score": 0.0,
                "risk_level": "ERROR",
                "passed": False
            }

    def _run_keyword_analysis(self, content: str, target_keywords: Optional[List[str]] = None) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            analysis_result = self.keyword_analyzer.analyze_keyword_density(content, target_keywords)
            quality_score = analysis_result.get("quality_score", {})

            return {
                "success": True,
                "overall_score": quality_score.get("overall_score", 0.0),
                "density_score": quality_score.get("density_score", 0.0),
                "distribution_score": quality_score.get("distribution_score", 0.0),
                "rating": quality_score.get("rating", "POOR"),
                "passed": quality_score.get("passed", False),
                "keyword_details": analysis_result.get("keyword_analysis", {}),
                "density_evaluation": analysis_result.get("density_evaluation", {}),
                "recommendations": analysis_result.get("recommendations", [])
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "overall_score": 0.0,
                "rating": "ERROR",
                "passed": False
            }

    def _run_personal_analysis(self, content: str, original_review: str, category: Optional[str] = None) -> Dict[str, Any]:
        """ê°œì¸ ê²½í—˜ ì§„ì •ì„± ë¶„ì„ ì‹¤í–‰"""
        try:
            analysis_result = self.content_checker.analyze_personal_experience_ratio(original_review, content, category)
            overall_eval = analysis_result.get("overall_evaluation", {})

            return {
                "success": True,
                "weighted_score": overall_eval.get("weighted_score", 0.0),
                "quality_grade": overall_eval.get("quality_grade", "VERY_POOR"),
                "passed": overall_eval.get("passed", False),
                "naver_compliance": overall_eval.get("naver_compliance", False),
                "individual_scores": overall_eval.get("individual_scores", {}),
                "analysis_details": {
                    "similarity": analysis_result.get("similarity_analysis", {}),
                    "personal_expression": analysis_result.get("personal_expression_analysis", {}),
                    "experience_reflection": analysis_result.get("experience_reflection_analysis", {}),
                    "emotion_analysis": analysis_result.get("emotion_analysis", {}),
                    "specificity": analysis_result.get("specificity_analysis", {})
                },
                "recommendations": analysis_result.get("recommendations", [])
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "weighted_score": 0.0,
                "quality_grade": "ERROR",
                "passed": False
            }

    def _calculate_technical_quality(self, content: str, naver_analysis: Dict, keyword_analysis: Dict) -> Dict[str, Any]:
        """ê¸°ìˆ ì  í’ˆì§ˆ ì§€í‘œ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì½˜í…ì¸  ë©”íŠ¸ë¦­
            content_length = len(content)
            word_count = len(content.split())
            sentence_count = len([s for s in content.split('.') if s.strip()])

            # ê¸¸ì´ ì ìˆ˜ (800-2000ì ê¸°ì¤€)
            length_score = self._calculate_length_score(content_length)

            # ê°€ë…ì„± ì ìˆ˜ (í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê¸°ì¤€)
            avg_sentence_length = word_count / max(sentence_count, 1)
            readability_score = self._calculate_readability_score(avg_sentence_length)

            # êµ¬ì¡° ì ìˆ˜ (í•´ì‹œíƒœê·¸, ë‹¨ë½ êµ¬ì„± ë“±)
            structure_score = self._calculate_structure_score(content)

            # ì¢…í•© ê¸°ìˆ ì  í’ˆì§ˆ ì ìˆ˜
            technical_score = (length_score + readability_score + structure_score) / 3

            return {
                "success": True,
                "technical_score": round(technical_score, 3),
                "length_score": round(length_score, 3),
                "readability_score": round(readability_score, 3),
                "structure_score": round(structure_score, 3),
                "metrics": {
                    "content_length": content_length,
                    "word_count": word_count,
                    "sentence_count": sentence_count,
                    "avg_sentence_length": round(avg_sentence_length, 1)
                },
                "passed": technical_score >= 0.6
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "technical_score": 0.0,
                "passed": False
            }

    def _calculate_unified_quality_score(self, naver: Dict, keyword: Dict, personal: Optional[Dict], technical: Dict) -> Dict[str, Any]:
        """í†µí•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê° ì˜ì—­ë³„ ì ìˆ˜ ì¶”ì¶œ
            scores = {
                "naver_compliance": naver.get("quality_score", 0.0),
                "keyword_quality": keyword.get("overall_score", 0.0),
                "personal_authenticity": personal.get("weighted_score", 0.7) if personal else 0.7,  # ê°œì¸ë¶„ì„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                "technical_quality": technical.get("technical_score", 0.0)
            }

            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_score = sum(scores[key] * self.VALIDATION_WEIGHTS[key] for key in scores.keys())

            # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
            quality_grade = self._determine_quality_grade(weighted_score)

            # ë„¤ì´ë²„ ì •ì±… í†µê³¼ ì—¬ë¶€
            naver_pass = weighted_score >= self.NAVER_PASS_THRESHOLD

            # ì „ì²´ í†µê³¼ ì—¬ë¶€ (ëª¨ë“  ì£¼ìš” ê²€ì¦ í†µê³¼)
            all_pass = (
                naver.get("passed", False) and
                keyword.get("passed", False) and
                technical.get("passed", False) and
                (personal.get("passed", True) if personal else True)  # ê°œì¸ë¶„ì„ ì—†ìœ¼ë©´ ê¸°ë³¸ í†µê³¼
            )

            return {
                "weighted_score": round(weighted_score, 3),
                "quality_grade": quality_grade,
                "naver_policy_compliance": naver_pass,
                "overall_passed": all_pass,

                "component_scores": scores,
                "component_weights": self.VALIDATION_WEIGHTS,

                "detailed_pass_status": {
                    "naver_validation": naver.get("passed", False),
                    "keyword_analysis": keyword.get("passed", False),
                    "personal_authenticity": personal.get("passed", True) if personal else True,
                    "technical_quality": technical.get("passed", False)
                },

                "confidence_level": self._calculate_confidence_level(naver, keyword, personal, technical)
            }

        except Exception as e:
            return {
                "weighted_score": 0.0,
                "quality_grade": "ERROR",
                "naver_policy_compliance": False,
                "overall_passed": False,
                "error": str(e)
            }

    def _calculate_length_score(self, length: int) -> float:
        """ì½˜í…ì¸  ê¸¸ì´ ì ìˆ˜ ê³„ì‚°"""
        if length < 300:
            return 0.3  # ë„ˆë¬´ ì§§ìŒ
        elif length < 600:
            return 0.6  # ì§§ìŒ
        elif length <= 2000:
            return 1.0  # ì ì ˆ
        elif length <= 3000:
            return 0.8  # ì¡°ê¸ˆ ê¹€
        else:
            return 0.5  # ë„ˆë¬´ ê¹€

    def _calculate_readability_score(self, avg_sentence_length: float) -> float:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê¸°ì¤€)"""
        if avg_sentence_length < 10:
            return 0.7  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ë“¤
        elif avg_sentence_length <= 20:
            return 1.0  # ì ì ˆí•œ ê¸¸ì´
        elif avg_sentence_length <= 30:
            return 0.8  # ì¡°ê¸ˆ ê¸´ ë¬¸ì¥ë“¤
        else:
            return 0.5  # ë„ˆë¬´ ê¸´ ë¬¸ì¥ë“¤

    def _calculate_structure_score(self, content: str) -> float:
        """êµ¬ì¡° ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # í•´ì‹œíƒœê·¸ ì¡´ì¬ ì—¬ë¶€
        if '#' in content:
            score += 0.3

        # ë‹¨ë½ êµ¬ë¶„ ì—¬ë¶€ (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)
        if '\n\n' in content:
            score += 0.4

        # ì ì ˆí•œ ë¬¸ì¥ ë¶€í˜¸ ì‚¬ìš©
        punctuation_count = content.count('.') + content.count('!') + content.count('?')
        if punctuation_count >= 3:
            score += 0.3

        return min(score, 1.0)

    def _determine_quality_grade(self, score: float) -> str:
        """í’ˆì§ˆ ë“±ê¸‰ ê²°ì •"""
        for grade, threshold in self.QUALITY_THRESHOLDS.items():
            if score >= threshold:
                return grade
        return "VERY_POOR"

    def _calculate_confidence_level(self, naver: Dict, keyword: Dict, personal: Optional[Dict], technical: Dict) -> str:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        success_count = sum([
            1 if naver.get("success", False) else 0,
            1 if keyword.get("success", False) else 0,
            1 if personal and personal.get("success", False) else 0.5,  # ê°œì¸ë¶„ì„ì€ ì„ íƒì‚¬í•­ì´ë¯€ë¡œ 0.5ì 
            1 if technical.get("success", False) else 0
        ])

        max_possible = 4 if personal else 3.5
        confidence_ratio = success_count / max_possible

        if confidence_ratio >= 0.9:
            return "HIGH"
        elif confidence_ratio >= 0.7:
            return "MEDIUM"
        else:
            return "LOW"

    def _generate_real_time_feedback(self, unified_score: Dict, naver: Dict, keyword: Dict, personal: Optional[Dict]) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±"""
        feedback = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "PASS" if unified_score.get("overall_passed", False) else "FAIL",
            "quality_grade": unified_score.get("quality_grade", "UNKNOWN"),
            "immediate_actions": [],
            "improvement_suggestions": [],
            "priority_fixes": []
        }

        # ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•œ í•­ëª©ë“¤
        if not naver.get("passed", False):
            feedback["immediate_actions"].append("âš ï¸ ë„¤ì´ë²„ ì •ì±… ìœ„ë°˜ ìš”ì†Œ ìˆ˜ì • í•„ìš”")
            feedback["priority_fixes"].extend(naver.get("recommendations", [])[:2])

        if not keyword.get("passed", False):
            feedback["immediate_actions"].append("ğŸ” í‚¤ì›Œë“œ ë°€ë„ ë° ë¶„í¬ ì¡°ì • í•„ìš”")
            feedback["priority_fixes"].extend(keyword.get("recommendations", [])[:2])

        # ê°œì„  ì œì•ˆì‚¬í•­
        score = unified_score.get("weighted_score", 0)
        if score < 0.8:
            if personal and personal.get("weighted_score", 0) < 0.7:
                feedback["improvement_suggestions"].append("ğŸ‘¤ ê°œì¸ ê²½í—˜ í‘œí˜„ì„ ë” ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”")

            if keyword.get("overall_score", 0) < 0.8:
                feedback["improvement_suggestions"].append("ğŸ”‘ í‚¤ì›Œë“œ ì‚¬ìš©ì„ ë” ìì—°ìŠ¤ëŸ½ê²Œ ë¶„ì‚°ì‹œí‚¤ì„¸ìš”")

        # ì ìˆ˜ë³„ ë©”ì‹œì§€
        if score >= 0.9:
            feedback["overall_message"] = "ğŸ‰ íƒì›”í•œ í’ˆì§ˆì˜ ì½˜í…ì¸ ì…ë‹ˆë‹¤!"
        elif score >= 0.8:
            feedback["overall_message"] = "âœ… ë§¤ìš° ì¢‹ì€ í’ˆì§ˆì…ë‹ˆë‹¤. ë°œí–‰ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
        elif score >= 0.7:
            feedback["overall_message"] = "ğŸ‘ ì–‘í˜¸í•œ í’ˆì§ˆì…ë‹ˆë‹¤. ì•½ê°„ì˜ ê°œì„  í›„ ë°œí–‰ ê¶Œì¥."
        elif score >= 0.6:
            feedback["overall_message"] = "âš ï¸ ë³´í†µ í’ˆì§ˆì…ë‹ˆë‹¤. ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            feedback["overall_message"] = "âŒ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ëŒ€í­ì ì¸ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."

        return feedback

    def get_quality_report(self, analysis_result: Dict[str, Any]) -> str:
        """ì‚¬ìš©ì ì¹œí™”ì ì¸ í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±"""
        unified = analysis_result["unified_score"]
        feedback = analysis_result["real_time_feedback"]

        report = f"""
=== ğŸ“Š ë¸”ë¡œê·¸ ì½˜í…ì¸  í’ˆì§ˆ ë¶„ì„ ë³´ê³ ì„œ ===

ğŸ¯ ì¢…í•© ì ìˆ˜: {unified['weighted_score']:.3f} ({unified['quality_grade']})
âœ… ì „ì²´ í†µê³¼: {'í†µê³¼' if unified['overall_passed'] else 'ë¯¸í†µê³¼'}
ğŸ›ï¸ ë„¤ì´ë²„ ì •ì±…: {'ì¤€ìˆ˜' if unified['naver_policy_compliance'] else 'ë¯¸ì¤€ìˆ˜'}

ğŸ“ˆ ì„¸ë¶€ ì ìˆ˜:
â€¢ ë„¤ì´ë²„ ì •ì±… ì¤€ìˆ˜: {unified['component_scores']['naver_compliance']:.2f} (35%)
â€¢ í‚¤ì›Œë“œ í’ˆì§ˆ: {unified['component_scores']['keyword_quality']:.2f} (25%)
â€¢ ê°œì¸ ê²½í—˜ ì§„ì •ì„±: {unified['component_scores']['personal_authenticity']:.2f} (25%)
â€¢ ê¸°ìˆ ì  í’ˆì§ˆ: {unified['component_scores']['technical_quality']:.2f} (15%)

{feedback['overall_message']}

âš¡ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”:
{chr(10).join(f"â€¢ {action}" for action in feedback['immediate_actions']) if feedback['immediate_actions'] else "â€¢ ì—†ìŒ"}

ğŸ’¡ ê°œì„  ì œì•ˆ:
{chr(10).join(f"â€¢ {suggestion}" for suggestion in feedback['improvement_suggestions']) if feedback['improvement_suggestions'] else "â€¢ í˜„ì¬ í’ˆì§ˆ ìœ ì§€"}

ë¶„ì„ ì‹œê°„: {analysis_result['analysis_duration_seconds']}ì´ˆ
"""
        return report.strip()